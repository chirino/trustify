name: ci-ai

on:
  workflow_dispatch:
  push:
    branches:
      - main
  merge_group:
    types:
      - checks_requested
  pull_request:
    branches:
      - main

env:
  CARGO_TERM_COLOR: always
  OLLAMA_VERSION: '0.4.2'
  OLLAMA_MODEL: 'llama3.1:8b'

jobs:

  ci-ai:
    runs-on: ubuntu-latest
    steps:
      - name: Maximize build space
        run: |
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
          sudo rm -Rf ${JAVA_HOME_8_X64}
          sudo rm -Rf ${JAVA_HOME_11_X64}
          sudo rm -Rf ${JAVA_HOME_17_X64}
          sudo rm -Rf ${RUBY_PATH}
          df -h

      - uses: actions/checkout@v4
      - uses: Swatinem/rust-cache@v2
      - name: Cache ollama
        uses: actions/cache@v3
        with:
          path: |
            /tmp/ollama-install.sh
            /usr/share/ollama/.ollama/models
          key: ${{ runner.os }}-ollama-${{ env.OLLAMA_VERSION }}-${{ env.OLLAMA_MODEL }}

      - name: Install ollama
        run: | 
          if [ ! -f /tmp/ollama-install.sh ]; then
            curl -fsSL https://ollama.com/install.sh > /tmp/ollama-install.sh
          fi
          cat /tmp/ollama-install.sh | sh
      - name: Run ollama
        run: |
          ollama serve &
          ollama pull ${{ env.OLLAMA_MODEL }}
      - name: Test
        run: 'cargo test -p trustify-module-fundamental ai:: -- --nocapture'
        env:
          RUST_LOG: trustify_module_fundamental::ai=info,langchain_rust=info
          OPENAI_API_KEY: ollama
          OPENAI_API_BASE: http://localhost:11434/v1
          OPENAI_MODEL: ${{ env.OLLAMA_MODEL }}
